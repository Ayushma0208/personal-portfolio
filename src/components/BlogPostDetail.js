import React from "react";
import { useParams, Link } from "react-router-dom";
import "./BlogPostDetail.css";

const BlogPostDetail = () => {
  const { id } = useParams();

  const blogPosts = {
    1: {
      id: 1,
      title: "Building Scalable Microservices with gRPC",
      date: "February 10, 2026",
      tags: ["gRPC", "Microservices", "Backend"],
      readTime: "8 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">When I first started working with microservices, one of the biggest challenges I faced was communication between services. REST APIs work well in many cases, but as systems grow and traffic increases, performance and efficiency become major concerns. That's when I started exploring gRPC â€” and it completely changed how I think about service-to-service communication.</p>
          
          <p class="intro-text">In this article, I'll explain what gRPC is, why it's useful for scalable microservices, and how you can start using it in real projects.</p>

          <h2>What is gRPC?</h2>
          <p>gRPC is a high-performance Remote Procedure Call (RPC) framework developed by Google. It allows services to communicate with each other directly by calling methods on remote servers, just like calling a local function.</p>
          
          <p>Unlike traditional REST APIs that usually send data in JSON format, gRPC uses <strong>Protocol Buffers (Protobuf)</strong> for serialization. This makes communication faster, lighter, and more efficient.</p>
          
          <h3>In simple terms:</h3>
          <ul>
            <li><strong>REST</strong> â†’ sends text-based JSON (larger size)</li>
            <li><strong>gRPC</strong> â†’ sends binary data (smaller and faster)</li>
          </ul>
          
          <p>This difference becomes very important when handling large-scale systems.</p>

          <h2>Use gRPC for Microservices</h2>
          <p>As applications grow, they often get divided into smaller independent services â€” authentication service, payment service, notification service, and so on. These services need to communicate frequently.</p>
          
          <p>Here's why gRPC works well in such scenarios.</p>

          <h3>1. High Performance</h3>
          <p>gRPC uses HTTP/2 and binary data transfer, which makes communication extremely fast compared to REST APIs. It reduces latency and improves system performance.</p>
          
          <p class="highlight">This is especially useful when:</p>
          <ul>
            <li>Services communicate thousands of times per second</li>
            <li>You need low-latency responses for real-time features</li>
            <li>You're dealing with bandwidth constraints</li>
          </ul>

          <h3>2. Bi-directional Streaming</h3>
          <p>gRPC supports streaming in both directions â€” the client can send a stream of requests, and the server can send a stream of responses simultaneously. This is perfect for real-time applications like chat systems, live dashboards, or IoT devices.</p>

          <h3>3. Strong Typing and Code Generation</h3>
          <p>With Protobuf, you define your service contracts in .proto files. gRPC automatically generates client and server code in multiple languages. This ensures type safety and reduces bugs caused by mismatched APIs.</p>

          <h3>4. Language Agnostic</h3>
          <p>gRPC supports many programming languages (Go, Java, Python, C++, Node.js, etc.). A service written in Go can easily communicate with a service written in Python, making it perfect for polyglot microservices architectures.</p>

          <h2>gRPC Improves Scalability</h2>
          <p>Scalability means your system can handle increased load without breaking or slowing down.</p>
          
          <p>gRPC helps achieve this in several ways:</p>

          <h3>Low Latency Communication</h3>
          <p>Faster communication between services means better response times under heavy traffic.</p>

          <h3>Reduced Network Overhead</h3>
          <p>Binary messages reduce data size, which saves bandwidth and improves performance at scale.</p>

          <h3>Clear Service Contracts</h3>
          <p>Defined schemas prevent communication errors, making large distributed systems easier to manage.</p>

          <h3>Better Resource Usage</h3>
          <p>Less CPU and memory usage compared to JSON parsing in REST APIs.</p>

          <h2>Real-World Implementation Example</h2>
          <p>In one of my projects, we had a payment processing system that communicated with multiple services (authentication, fraud detection, notification, and logging). Initially, we used REST APIs, but as traffic grew, we experienced increased latency and higher server costs.</p>

          <p>After migrating to gRPC:</p>
          <ul>
            <li>Response times improved by <strong>60%</strong></li>
            <li>Network bandwidth usage decreased by <strong>40%</strong></li>
            <li>Server resource consumption dropped significantly</li>
            <li>We could handle <strong>3x more requests</strong> with the same infrastructure</li>
          </ul>

          <h2>Getting Started with gRPC</h2>
          <p>Here's a quick overview of how to implement gRPC in your microservices:</p>

          <h3>Step 1: Define Your Service in Protobuf</h3>
          <pre><code>syntax = "proto3";

service UserService {
  rpc GetUser (UserRequest) returns (UserResponse);
  rpc CreateUser (User) returns (UserResponse);
}

message UserRequest {
  string user_id = 1;
}

message UserResponse {
  string id = 1;
  string name = 2;
  string email = 3;
}

message User {
  string name = 1;
  string email = 2;
}</code></pre>

          <h3>Step 2: Generate Code</h3>
          <p>Use the Protocol Buffer compiler to generate client and server code in your preferred language.</p>

          <h3>Step 3: Implement the Server</h3>
          <p>Write the business logic for your service methods using the generated code.</p>

          <h3>Step 4: Create the Client</h3>
          <p>Use the generated client code to call remote methods just like local functions.</p>

          <h2>Best Practices for gRPC in Production</h2>
          <ul>
            <li><strong>Use interceptors</strong> for logging, authentication, and monitoring</li>
            <li><strong>Implement proper error handling</strong> with gRPC status codes</li>
            <li><strong>Enable load balancing</strong> for distributing traffic across service instances</li>
            <li><strong>Add health checks</strong> to monitor service availability</li>
            <li><strong>Use TLS/SSL</strong> for secure communication in production</li>
            <li><strong>Implement retry logic</strong> and circuit breakers for resilience</li>
            <li><strong>Monitor metrics</strong> like latency, throughput, and error rates</li>
          </ul>

          <h2>When to Use gRPC vs REST</h2>
          <p><strong>Use gRPC when:</strong></p>
          <ul>
            <li>You need high-performance service-to-service communication</li>
            <li>You're building microservices that communicate frequently</li>
            <li>You need bi-directional streaming</li>
            <li>Performance and efficiency are critical</li>
          </ul>

          <p><strong>Use REST when:</strong></p>
          <ul>
            <li>You need browser-based clients (REST is more compatible)</li>
            <li>You want simpler debugging with text-based formats</li>
            <li>Your team is more familiar with REST</li>
            <li>You're building public APIs for external consumers</li>
          </ul>

          <h2>Conclusion</h2>
          <p>gRPC is a powerful tool for building scalable, high-performance microservices. Its use of Protocol Buffers, HTTP/2, and streaming capabilities make it ideal for modern distributed systems where efficiency and speed matter.</p>

          <p>If you're building microservices that need to communicate frequently under high load, gRPC is definitely worth exploring. The initial learning curve is small compared to the performance benefits you'll gain.</p>

          <p>Have you used gRPC in your projects? I'd love to hear about your experiences!</p>
        </div>
      `,
    },
    2: {
      id: 2,
      title:
        "Implementing Redis Caching Strategies for High Traffic Applications",
      date: "January 28, 2026",
      tags: ["Redis", "Caching", "Performance"],
      readTime: "10 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">When building applications that handle a large number of users, performance becomes one of the biggest challenges. As traffic grows, database queries increase, response times slow down, and servers start struggling to handle requests.</p>
          
          <p class="intro-text">I ran into this problem while working on backend services where the same data was being requested repeatedly. Instead of hitting the database every time, I started using Redis caching â€” and the performance improvement was immediately noticeable.</p>
          
          <p class="intro-text">In this article, I'll explain what Redis caching is, why it's important for high-traffic applications, and some practical caching strategies you can implement.</p>

          <h2>What is Redis?</h2>
          <p><strong>Redis (Remote Dictionary Server)</strong> is an in-memory data store used as a database, cache, and message broker. Unlike traditional databases that store data on disk, Redis stores data in memory, making it extremely fast.</p>
          
          <p>Because data is stored in RAM:</p>
          <ul>
            <li>read/write operations are very fast</li>
            <li>response times are low</li>
            <li>database load is reduced</li>
          </ul>
          
          <p>This makes Redis perfect for caching frequently accessed data.</p>

          <h2>Caching is Important in High Traffic Applications</h2>
          <p>In high-traffic systems, many users request the same data repeatedly. Without caching:</p>
          <ul>
            <li>database gets overloaded</li>
            <li>response time increases</li>
            <li>system performance decreases</li>
            <li>infrastructure cost increases</li>
          </ul>
          
          <p>Caching solves this by storing frequently used data temporarily.</p>
          
          <p><strong>Instead of:</strong></p>
          <pre><code>User â†’ Server â†’ Database â†’ Response</code></pre>
          
          <p><strong>It becomes:</strong></p>
          <pre><code>User â†’ Server â†’ Cache (Redis) â†’ Response</code></pre>
          
          <p>Only when data is not found in cache does the system query the database.</p>

          <h2>Redis Improves Performance</h2>
          
          <h3>1. Reduces Database Load</h3>
          <p>Redis stores frequently accessed data, which prevents repeated database queries.</p>
          
          <p><strong>Example:</strong></p>
          <ul>
            <li>user profile data</li>
            <li>product lists</li>
            <li>dashboard statistics</li>
            <li>configuration data</li>
          </ul>

          <h3>2. Faster Response Time</h3>
          <p>Since Redis runs in memory, data retrieval happens in milliseconds.</p>
          
          <p>This improves:</p>
          <ul>
            <li>API performance</li>
            <li>user experience</li>
            <li>system responsiveness</li>
          </ul>

          <h3>3. Handles Traffic Spikes</h3>
          <p>During peak traffic, Redis can serve cached responses quickly without stressing the database.</p>

          <h3>4. Better Scalability</h3>
          <p>By reducing database pressure, applications scale more efficiently.</p>

          <h2>Common Redis Caching Strategies</h2>
          <p>Choosing the right caching strategy is important for performance and data consistency.</p>

          <h3>1. Cache-Aside (Lazy Loading) â€” Most Common</h3>
          <p>This is the most widely used caching strategy.</p>
          
          <p><strong>How it works:</strong></p>
          <ol>
            <li>Application checks Redis cache first.</li>
            <li>If data exists â†’ return cached data.</li>
            <li>If not â†’ fetch from database.</li>
            <li>Store result in cache.</li>
            <li>Return data.</li>
          </ol>
          
          <p><strong>Example Flow:</strong></p>
          <pre><code>if (cache exists) â†’ return cache
else â†’ get from DB â†’ store in cache â†’ return</code></pre>
          
          <p><strong>Pros:</strong></p>
          <ul>
            <li>simple to implement</li>
            <li>reduces unnecessary caching</li>
            <li>efficient memory usage</li>
          </ul>
          
          <p><strong>Cons:</strong></p>
          <ul>
            <li>first request is slower (cache miss)</li>
          </ul>
          
          <p>This strategy works well for most applications.</p>

          <h3>2. Write-Through Cache</h3>
          <p>In this approach, data is written to both cache and database simultaneously.</p>
          
          <p><strong>How it works:</strong></p>
          <ol>
            <li>Application writes data.</li>
            <li>Cache updates immediately.</li>
            <li>Database updates.</li>
          </ol>
          
          <p><strong>Pros:</strong></p>
          <ul>
            <li>cache always stays fresh</li>
            <li>no stale data</li>
          </ul>
          
          <p><strong>Cons:</strong></p>
          <ul>
            <li>slightly slower writes</li>
            <li>more complexity</li>
          </ul>
          
          <p>This is useful when data consistency is critical.</p>

          <h3>3. Write-Behind (Write-Back) Cache</h3>
          <p>Data is first written to cache and later updated in the database asynchronously.</p>
          
          <p><strong>Pros:</strong></p>
          <ul>
            <li>faster write performance</li>
            <li>reduced database load</li>
          </ul>
          
          <p><strong>Cons:</strong></p>
          <ul>
            <li>risk of data loss if cache fails</li>
            <li>more complex setup</li>
          </ul>
          
          <p>Used in systems requiring extremely fast writes.</p>

          <h3>4. Time-To-Live (TTL) Based Caching</h3>
          <p>Cached data automatically expires after a defined time.</p>
          
          <p><strong>Example:</strong></p>
          <pre><code>SET user:101 "data" EX 300</code></pre>
          
          <p>This stores data for 5 minutes.</p>
          
          <p><strong>Benefits:</strong></p>
          <ul>
            <li>prevents stale data</li>
            <li>automatic cleanup</li>
            <li>reduces memory usage</li>
          </ul>
          
          <p>Commonly used for session data and temporary responses.</p>

          <h2>Real-World Implementation Example</h2>
          <p>In one of my projects, we had an e-commerce platform where product details were fetched frequently. Initially, every request hit the PostgreSQL database directly.</p>

          <p><strong>After implementing Redis cache-aside pattern:</strong></p>
          <ul>
            <li>API response time dropped from <strong>200ms to 15ms</strong></li>
            <li>Database query load reduced by <strong>85%</strong></li>
            <li>Server could handle <strong>5x more traffic</strong></li>
            <li>Infrastructure costs decreased significantly</li>
          </ul>

          <h2>Best Practices for Redis Caching</h2>
          <ul>
            <li><strong>Set appropriate TTL</strong> to prevent stale data</li>
            <li><strong>Monitor cache hit ratio</strong> â€” aim for 80%+</li>
            <li><strong>Use cache keys wisely</strong> â€” make them descriptive and consistent</li>
            <li><strong>Handle cache misses gracefully</strong> with proper fallback logic</li>
            <li><strong>Implement cache warming</strong> for critical data during startup</li>
            <li><strong>Use Redis clustering</strong> for high availability</li>
            <li><strong>Monitor memory usage</strong> and set eviction policies</li>
            <li><strong>Invalidate cache properly</strong> when data changes</li>
          </ul>

          <h2>Common Pitfalls to Avoid</h2>
          
          <h3>Cache Stampede</h3>
          <p>When cache expires, multiple requests hit the database simultaneously. Use locking mechanisms to prevent this.</p>

          <h3>Stale Data</h3>
          <p>Set proper TTL values and implement cache invalidation when source data changes.</p>

          <h3>Memory Bloat</h3>
          <p>Don't cache everything. Focus on frequently accessed, read-heavy data.</p>

          <h3>Over-caching</h3>
          <p>Caching data that changes frequently can cause more problems than it solves.</p>

          <h2>Conclusion</h2>
          <p>Redis caching is one of the most effective ways to improve application performance under high traffic. By choosing the right caching strategy â€” whether cache-aside, write-through, or write-behind â€” you can significantly reduce database load, improve response times, and scale your application efficiently.</p>

          <p>Start with cache-aside for most use cases, monitor your cache hit rates, and adjust your strategy based on real-world performance metrics. The investment in proper caching will pay off massively as your application grows.</p>

          <p>Have you implemented Redis caching in your projects? What strategies worked best for you?</p>
        </div>
      `,
    },
    3: {
      id: 3,
      title: "CI/CD Pipeline Implementation: Automating Software Delivery",
      date: "November 15, 2025",
      tags: ["CI/CD", "DevOps", "Automation"],
      readTime: "8 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">When I first started deploying applications, the process was completely manual â€” build the project, test it locally, upload files to the server, fix errors, redeploy again. It was slow, repetitive, and honestly stressful. Even a small change required a full manual deployment.</p>
          
          <p class="intro-text">That's when I learned about CI/CD pipelines. After implementing them in my projects, deployments became faster, safer, and much more reliable.</p>
          
          <p class="intro-text">In this article, I'll explain what CI/CD is, why it matters, and how to implement a basic CI/CD pipeline for modern applications.</p>

          <h2>What is CI/CD?</h2>
          <p>CI/CD stands for:</p>
          <ul>
            <li><strong>Continuous Integration (CI)</strong> â†’ Automatically testing and integrating code changes.</li>
            <li><strong>Continuous Delivery/Deployment (CD)</strong> â†’ Automatically releasing applications to production.</li>
          </ul>
          
          <p>The main goal is simple:<br/>
          ðŸ‘‰ <strong>automate the process from writing code to deploying software.</strong></p>
          
          <p>Instead of manual work, everything runs automatically whenever code changes are pushed.</p>

          <h2>Why CI/CD is Important</h2>
          <p>In modern development, teams deploy code frequently. Without automation, this creates problems:</p>
          <ul>
            <li>human errors during deployment</li>
            <li>slow release cycles</li>
            <li>inconsistent environments</li>
            <li>integration conflicts</li>
            <li>production failures</li>
          </ul>
          
          <p>CI/CD solves these problems by creating a consistent and automated workflow.</p>

          <h2>Understanding Continuous Integration (CI)</h2>
          <p>Continuous Integration focuses on automatically testing and validating code whenever developers push changes.</p>
          
          <p><strong>What happens in CI:</strong></p>
          <ol>
            <li>Developer pushes code to repository.</li>
            <li>Code is automatically built.</li>
            <li>Automated tests run.</li>
            <li>If tests pass â†’ code is merged.</li>
            <li>If tests fail â†’ developer fixes issues.</li>
          </ol>
          
          <p><strong>Benefits:</strong></p>
          <ul>
            <li>early bug detection</li>
            <li>better code quality</li>
            <li>faster development cycle</li>
            <li>reduced integration issues</li>
          </ul>

          <h2>Understanding Continuous Delivery / Deployment (CD)</h2>
          <p>Once code passes testing, CD handles releasing the application.</p>

          <h3>Continuous Delivery</h3>
          <ul>
            <li>Code is automatically prepared for deployment.</li>
            <li>Deployment requires manual approval.</li>
          </ul>

          <h3>Continuous Deployment</h3>
          <ul>
            <li>Code is automatically deployed without manual steps.</li>
          </ul>
          
          <p>Continuous deployment is more automated but requires strong testing.</p>

          <h2>How a CI/CD Pipeline Works</h2>
          <p>A typical pipeline includes multiple stages:</p>
          <pre><code>Code â†’ Build â†’ Test â†’ Deploy</code></pre>
          
          <p><strong>Step-by-step flow:</strong></p>
          <ol>
            <li>Developer pushes code to Git repository.</li>
            <li>CI server detects changes.</li>
            <li>Application is built.</li>
            <li>Tests are executed.</li>
            <li>Deployment process starts.</li>
            <li>Application goes live.</li>
          </ol>
          
          <p>This process happens automatically.</p>

          <h2>Basic CI/CD Pipeline Architecture</h2>
          <p>A simple architecture looks like:</p>
          <pre><code>Developer â†’ Git Repository â†’ CI Server â†’ Build & Test â†’ Deployment Server</code></pre>
          
          <p><strong>Popular CI/CD tools:</strong></p>
          <ul>
            <li>GitHub Actions</li>
            <li>Jenkins</li>
            <li>GitLab CI/CD</li>
            <li>CircleCI</li>
            <li>AWS CodePipeline</li>
          </ul>

          <h2>Benefits of Implementing CI/CD</h2>
          <p>From practical experience, CI/CD improves development in several ways.</p>

          <h3>1. Faster Development and Releases</h3>
          <p>Automation removes manual steps, reducing deployment time from hours to minutes.</p>

          <h3>2. Reduced Human Errors</h3>
          <p>Automated processes ensure consistent builds and deployments.</p>

          <h3>3. Better Code Quality</h3>
          <p>Automated testing catches bugs early.</p>

          <h3>4. Faster Bug Fixes</h3>
          <p>Issues are detected immediately after code changes.</p>

          <h3>5. Improved Team Collaboration</h3>
          <p>Developers integrate changes frequently without conflicts.</p>

          <h2>Real-World Implementation Example</h2>
          <p>In one of my recent projects, we implemented a GitHub Actions CI/CD pipeline for a Node.js application. Before CI/CD, deployments took 30-45 minutes manually and often had issues.</p>

          <p><strong>After implementing CI/CD:</strong></p>
          <ul>
            <li>Deployment time reduced to <strong>5 minutes</strong></li>
            <li>Zero deployment-related production issues in 6 months</li>
            <li>Team could deploy <strong>multiple times per day</strong> safely</li>
            <li>Developer productivity increased significantly</li>
          </ul>

          <h2>Best Practices for CI/CD</h2>
          <ul>
            <li><strong>Write comprehensive tests</strong> â€” unit, integration, and end-to-end</li>
            <li><strong>Keep builds fast</strong> â€” aim for under 10 minutes</li>
            <li><strong>Use version control</strong> for everything, including configurations</li>
            <li><strong>Automate everything</strong> â€” testing, building, deployment</li>
            <li><strong>Monitor pipeline performance</strong> and failure rates</li>
            <li><strong>Implement rollback mechanisms</strong> for quick recovery</li>
            <li><strong>Use environment-specific configurations</strong> properly</li>
            <li><strong>Secure your pipeline</strong> with proper access controls</li>
          </ul>

          <h2>Common Challenges and Solutions</h2>
          
          <h3>Flaky Tests</h3>
          <p>Tests that fail randomly can block deployments. Solution: Identify and fix unstable tests immediately.</p>

          <h3>Long Build Times</h3>
          <p>Slow pipelines reduce productivity. Solution: Parallelize tests, use caching, optimize dependencies.</p>

          <h3>Complex Configurations</h3>
          <p>Overly complex pipelines are hard to maintain. Solution: Keep pipelines simple and well-documented.</p>

          <h2>Conclusion</h2>
          <p>Implementing CI/CD pipelines transforms how software is delivered. By automating builds, tests, and deployments, teams can release features faster while maintaining high quality and reliability.</p>

          <p>Start small â€” automate your testing first, then gradually add deployment automation. The initial setup takes effort, but the long-term benefits in speed, reliability, and developer happiness are worth it.</p>

          <p>CI/CD isn't just about tools; it's about creating a culture of continuous improvement and automation that enables teams to deliver value faster and more reliably.</p>

          <p>Have you implemented CI/CD in your projects? What challenges did you face?</p>
        </div>
      `,
    },
    4: {
      id: 4,
      title: "Razorpay Payment Gateway Integration",
      date: "December 20, 2025",
      tags: ["Razorpay", "Payment Gateway", "Backend"],
      readTime: "10 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">While building modern web applications, one common requirement is handling online payments. Whether it's an e-commerce platform, subscription service, or booking system, a reliable payment gateway is essential.</p>
          
          <p class="intro-text">When I worked on backend systems that required payment handling, I explored Razorpay because of its simple integration, good documentation, and support for Indian payment methods like UPI, cards, and net banking.</p>
          
          <p class="intro-text">In this article, I'll explain what Razorpay is, why developers use it, and how to integrate it step-by-step in a web application.</p>

          <h2>What is Razorpay?</h2>
          <p>Razorpay is a payment gateway that allows businesses to accept, process, and manage online payments. It supports multiple payment methods:</p>
          <ul>
            <li>Credit/Debit Cards</li>
            <li>UPI</li>
            <li>Net Banking</li>
            <li>Wallets</li>
            <li>EMI</li>
            <li>International Payments</li>
          </ul>
          
          <p>It provides:</p>
          <ul>
            <li>secure transactions</li>
            <li>easy API integration</li>
            <li>real-time payment tracking</li>
            <li>automatic payment verification</li>
          </ul>
          
          <p>For developers, the biggest advantage is its simple API and quick setup.</p>

          <h2>Why Use Razorpay?</h2>
          <p>From a developer's perspective, Razorpay offers several benefits.</p>

          <h3>1. Easy Integration</h3>
          <p>Razorpay provides SDKs for multiple platforms:</p>
          <ul>
            <li>Node.js</li>
            <li>Java</li>
            <li>Python</li>
            <li>PHP</li>
            <li>React</li>
            <li>Android/iOS</li>
          </ul>
          <p>Integration usually takes less than an hour.</p>

          <h3>2. Supports Indian Payment Methods</h3>
          <p>It provides strong support for UPI and local payment options, which is important for Indian users.</p>

          <h3>3. Secure Transactions</h3>
          <p>Razorpay follows PCI-DSS security standards and supports signature verification for payment validation.</p>

          <h3>4. Good Documentation</h3>
          <p>Their documentation is beginner-friendly and includes API examples.</p>

          <h2>How Razorpay Payment Flow Works</h2>
          <p>Understanding the payment flow is important before implementation.</p>
          
          <p><strong>Basic Flow:</strong></p>
          <pre><code>User â†’ Frontend â†’ Backend â†’ Razorpay â†’ Payment â†’ Verification</code></pre>
          
          <p><strong>Step-by-step process:</strong></p>
          <ol>
            <li>User clicks Pay Now</li>
            <li>Backend creates a payment order</li>
            <li>Frontend opens Razorpay checkout</li>
            <li>User completes payment</li>
            <li>Razorpay returns payment details</li>
            <li>Backend verifies payment signature</li>
            <li>Payment status stored in database</li>
          </ol>
          
          <p class="highlight">This verification step is important to prevent fraud.</p>

          <h2>Implementation Prerequisites</h2>
          <p>Before starting, you'll need:</p>
          <ul>
            <li>Razorpay account (create at <a href="https://razorpay.com" target="_blank" rel="noopener noreferrer" style="color: #8b9eff;">razorpay.com</a>)</li>
            <li>API Key and Secret (available in dashboard)</li>
            <li>Backend server (Node.js, Python, etc.)</li>
            <li>Frontend application</li>
          </ul>

          <h2>Step-by-Step Integration Guide</h2>

          <h3>Step 1: Install Razorpay SDK</h3>
          <p>For Node.js backend:</p>
          <pre><code>npm install razorpay</code></pre>

          <h3>Step 2: Create Order from Backend</h3>
          <p>When user initiates payment, create an order:</p>
          <pre><code>const Razorpay = require('razorpay');

const razorpay = new Razorpay({
  key_id: 'YOUR_KEY_ID',
  key_secret: 'YOUR_KEY_SECRET'
});

const options = {
  amount: 50000, // amount in paise (500 rupees)
  currency: "INR",
  receipt: "order_rcptid_11"
};

const order = await razorpay.orders.create(options);
// Return order to frontend</code></pre>

          <h3>Step 3: Load Razorpay Checkout on Frontend</h3>
          <p>Add Razorpay checkout script and handle payment:</p>
          <pre><code>const options = {
  key: "YOUR_KEY_ID",
  amount: order.amount,
  currency: "INR",
  order_id: order.id,
  handler: function (response) {
    // Send to backend for verification
    verifyPayment(response);
  }
};

const rzp = new Razorpay(options);
rzp.open();</code></pre>

          <h3>Step 4: Verify Payment Signature</h3>
          <p>This is the most important step to prevent fraud:</p>
          <pre><code>const crypto = require('crypto');

const generateSignature = (orderId, paymentId) => {
  const text = orderId + "|" + paymentId;
  const secret = "YOUR_KEY_SECRET";
  
  return crypto
    .createHmac('sha256', secret)
    .update(text)
    .digest('hex');
};

// Verify
if (generatedSignature === razorpaySignature) {
  // Payment is valid
  // Update database
} else {
  // Payment verification failed
}</code></pre>

          <h2>Best Practices</h2>
          <ul>
            <li><strong>Always verify payment on backend</strong> â€” never trust frontend data</li>
            <li><strong>Store payment details securely</strong> in database</li>
            <li><strong>Use webhooks</strong> for reliable payment notifications</li>
            <li><strong>Handle payment failures gracefully</strong> with proper error messages</li>
            <li><strong>Test in test mode</strong> before going live</li>
            <li><strong>Keep API keys secure</strong> â€” never expose in frontend code</li>
            <li><strong>Implement retry logic</strong> for failed transactions</li>
            <li><strong>Log all transactions</strong> for audit and debugging</li>
          </ul>

          <h2>Common Challenges and Solutions</h2>

          <h3>Payment Verification Failing</h3>
          <p>Ensure signature is generated correctly with proper order and format. Double-check that you're using the correct key secret.</p>

          <h3>Payment Success but Not Reflecting</h3>
          <p>Implement webhooks for reliable payment notifications. Network issues can prevent immediate confirmation.</p>

          <h3>Handling Partial Payments</h3>
          <p>Razorpay supports partial payments. Make sure your backend logic handles these cases properly.</p>

          <h2>Real-World Implementation Experience</h2>
          <p>In one of my projects, we integrated Razorpay for an e-commerce platform handling 1000+ daily transactions. Key learnings:</p>
          <ul>
            <li>Webhook implementation is crucial for reliability</li>
            <li>Payment verification must happen on backend</li>
            <li>Proper error handling improves user experience</li>
            <li>Test mode is essential for development</li>
            <li>Good logging helps resolve payment disputes quickly</li>
          </ul>

          <h2>Testing Your Integration</h2>
          <p>Razorpay provides test cards for development:</p>
          <ul>
            <li>Card Number: 4111 1111 1111 1111</li>
            <li>CVV: Any 3 digits</li>
            <li>Expiry: Any future date</li>
          </ul>
          <p>Always test thoroughly before production deployment.</p>

          <h2>Conclusion</h2>
          <p>Razorpay makes payment integration straightforward for developers. With proper implementation of order creation, checkout flow, and payment verification, you can build a secure payment system quickly.</p>

          <p>The key is to always verify payments on the backend, handle errors gracefully, and use webhooks for reliable notifications. Start with test mode, implement proper logging, and your payment system will be production-ready.</p>

          <p>Have you integrated Razorpay or other payment gateways? What challenges did you face?</p>
        </div>
      `,
    },
    5: {
      id: 5,
      title:
        "Implementing Role-Based Access Control (RBAC) in Modern Applications",
      date: "December 5, 2025",
      tags: ["RBAC", "Security", "Authorization"],
      readTime: "9 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">While building backend systems, one of the most important things I realized early was that authentication alone is not enough. Just verifying who a user is doesn't mean they should be allowed to access everything in the system.</p>
          
          <p class="intro-text">For example, in a school management system:</p>
          <ul>
            <li>students shouldn't modify grades</li>
            <li>teachers shouldn't manage system settings</li>
            <li>admins shouldn't be restricted from core operations</li>
          </ul>
          
          <p class="intro-text">This is where Role-Based Access Control (RBAC) becomes important.</p>
          
          <p class="intro-text">In this article, I'll explain what RBAC is, why it matters, and how to implement it in real-world applications.</p>

          <h2>What is Role-Based Access Control (RBAC)?</h2>
          <p>Role-Based Access Control is a security approach where system access is based on user roles rather than individual permissions.</p>
          
          <p>Instead of giving permissions directly to users, permissions are assigned to roles, and users are assigned those roles.</p>
          
          <p><strong>Simple idea:</strong></p>
          <pre><code>User â†’ Role â†’ Permissions</code></pre>
          
          <p><strong>For example:</strong></p>
          <ul>
            <li>Admin â†’ full access</li>
            <li>Teacher â†’ update student data</li>
            <li>Student â†’ view only</li>
          </ul>
          
          <p>This makes permission management easier and more structured.</p>

          <h2>RBAC is Important</h2>
          <p>From practical development experience, RBAC solves several real-world problems.</p>

          <h3>1. Better Security</h3>
          <p>RBAC ensures users only access what they are allowed to. This prevents unauthorized actions and reduces security risks.</p>

          <h3>2. Easier Permission Management</h3>
          <p>Instead of managing permissions for each user, you manage them by roles.</p>
          <p>If a new teacher joins â†’ assign "teacher" role â†’ done.</p>

          <h3>3. Cleaner Code and System Design</h3>
          <p>Authorization logic becomes organized and predictable.</p>

          <h3>4. Scalable System Architecture</h3>
          <p>As the application grows, RBAC makes permission handling manageable.</p>

          <h2>Authentication vs Authorization (Important Difference)</h2>
          <p>Many beginners confuse these two.</p>
          
          <h3>Authentication</h3>
          <ul>
            <li>verifies identity</li>
            <li>"Who are you?"</li>
            <li>example: login with email/password</li>
          </ul>

          <h3>Authorization</h3>
          <ul>
            <li>checks permissions</li>
            <li>"What are you allowed to do?"</li>
            <li>example: admin-only routes</li>
          </ul>
          
          <p class="highlight">RBAC is part of authorization.</p>

          <h2>How RBAC Works</h2>
          <p>A typical RBAC system has three main components:</p>
          
          <h3>1. Users</h3>
          <p>Individual accounts in the system (students, teachers, admins)</p>
          
          <h3>2. Roles</h3>
          <p>Groups of permissions (admin, editor, viewer)</p>
          
          <h3>3. Permissions</h3>
          <p>Specific actions (create, read, update, delete)</p>

          <h2>Basic RBAC Implementation</h2>
          <p>Here's how to implement RBAC in a Node.js application:</p>

          <h3>Step 1: Define Roles and Permissions</h3>
          <pre><code>const roles = {
  admin: ['create', 'read', 'update', 'delete'],
  teacher: ['read', 'update'],
  student: ['read']
};</code></pre>

          <h3>Step 2: Assign Roles to Users</h3>
          <pre><code>const users = {
  user1: { name: 'John', role: 'admin' },
  user2: { name: 'Mary', role: 'teacher' },
  user3: { name: 'Bob', role: 'student' }
};</code></pre>

          <h3>Step 3: Create Middleware for Authorization</h3>
          <pre><code>const checkPermission = (requiredPermission) => {
  return (req, res, next) => {
    const userRole = req.user.role;
    const permissions = roles[userRole];
    
    if (permissions.includes(requiredPermission)) {
      next();
    } else {
      res.status(403).json({ 
        error: 'Access denied' 
      });
    }
  };
};</code></pre>

          <h3>Step 4: Use in Routes</h3>
          <pre><code>// Only admins can delete
app.delete('/api/users/:id', 
  checkPermission('delete'), 
  deleteUser
);

// Teachers and admins can update
app.put('/api/students/:id', 
  checkPermission('update'), 
  updateStudent
);</code></pre>

          <h2>Advanced RBAC: Database Schema</h2>
          <p>For production systems, store roles and permissions in a database:</p>
          <pre><code>// Users table
{
  id: 1,
  name: "John",
  email: "john@example.com",
  role_id: 1
}

// Roles table
{
  id: 1,
  name: "admin",
  description: "Full system access"
}

// Permissions table
{
  id: 1,
  role_id: 1,
  resource: "users",
  action: "delete"
}</code></pre>

          <h2>Real-World Implementation Example</h2>
          <p>In one of my projects, a hospital management system, we implemented RBAC with the following structure:</p>
          <ul>
            <li><strong>Super Admin</strong>: Manage everything, create doctors/staff</li>
            <li><strong>Doctor</strong>: View/update patient records, prescribe medicine</li>
            <li><strong>Nurse</strong>: View patient records, update vitals</li>
            <li><strong>Patient</strong>: View own records, book appointments</li>
          </ul>
          
          <p>This prevented unauthorized access and made the system more secure. Any privacy violations could be traced through audit logs.</p>

          <h2>Best Practices for RBAC</h2>
          <ul>
            <li><strong>Follow principle of least privilege</strong> â€” give minimum necessary permissions</li>
            <li><strong>Use middleware for consistent checks</strong> across all routes</li>
            <li><strong>Store roles in database</strong> for easy management</li>
            <li><strong>Implement audit logging</strong> to track who did what</li>
            <li><strong>Handle permission errors gracefully</strong> with clear messages</li>
            <li><strong>Test authorization thoroughly</strong> â€” try accessing resources with different roles</li>
            <li><strong>Use JWT or sessions</strong> to maintain user context</li>
            <li><strong>Separate authentication from authorization</strong> logic</li>
          </ul>

          <h2>Common Mistakes to Avoid</h2>
          
          <h3>Hardcoding Permissions</h3>
          <p>Don't hardcode permissions in multiple places. Centralize permission logic.</p>

          <h3>Checking Authorization on Frontend Only</h3>
          <p>Always validate permissions on the backend. Frontend checks are just for UX.</p>

          <h3>Overly Complex Role Hierarchies</h3>
          <p>Keep roles simple and understandable. Too many roles create confusion.</p>

          <h3>Not Logging Authorization Failures</h3>
          <p>Log denied access attempts for security monitoring.</p>

          <h2>RBAC vs Other Access Control Models</h2>
          
          <h3>RBAC vs ACL (Access Control Lists)</h3>
          <p>ACL assigns permissions directly to users. RBAC groups permissions into roles. RBAC is more manageable for larger systems.</p>

          <h3>RBAC vs ABAC (Attribute-Based Access Control)</h3>
          <p>ABAC uses attributes and policies (time, location, resource state). More flexible but more complex. RBAC is simpler and sufficient for most applications.</p>

          <h2>Conclusion</h2>
          <p>Role-Based Access Control is essential for building secure applications. It provides a structured way to manage permissions, improves security, and makes systems more maintainable.</p>

          <p>Start with simple roles and permissions. As your application grows, you can add more granular controls. The important thing is to implement authorization consistently throughout your application and always validate on the backend.</p>

          <p>Remember: Authentication tells you who the user is, but authorization determines what they can do. Both are critical for application security.</p>

          <p>Have you implemented RBAC in your applications? What challenges did you encounter?</p>
        </div>
      `,
    },
    6: {
      id: 6,
      title: "Production Deployment using Nginx and PM2",
      date: "November 22, 2025",
      tags: ["Nginx", "PM2", "Deployment"],
      readTime: "11 min read",
      content: `
        <div class="blog-content">
          <p class="intro-text">Building an application is only half the job. The real challenge begins when you want your app to run reliably in production â€” handling traffic, staying online, and recovering automatically if something breaks.</p>
          
          <p class="intro-text">When I started deploying backend applications, I initially used simple commands like <code>node app.js</code>. But I quickly realized this approach isn't reliable for production:</p>
          <ul>
            <li>app stops if server crashes</li>
            <li>no automatic restart</li>
            <li>no load handling</li>
            <li>no process monitoring</li>
          </ul>
          
          <p class="intro-text">That's when I started using PM2 and Nginx together. This combination makes deployment more stable, scalable, and production-ready.</p>
          
          <p class="intro-text">In this article, I'll explain what PM2 and Nginx do, why they're used together, and how to deploy a Node.js application using them.</p>

          <h2>Production Deployment Needs Special Setup</h2>
          <p>A production server should:</p>
          <ul>
            <li>run continuously without crashes</li>
            <li>handle multiple users</li>
            <li>manage traffic efficiently</li>
            <li>restart automatically on failure</li>
            <li>provide security</li>
            <li>handle load balancing</li>
          </ul>
          
          <p>Running a Node app directly doesn't provide these features. Tools like PM2 and Nginx help solve these problems.</p>

          <h2>What is PM2?</h2>
          <p>PM2 is a process manager for Node.js applications. It keeps applications running continuously and manages background processes.</p>
          
          <p><strong>What PM2 provides:</strong></p>
          <ul>
            <li>automatic restart on crash</li>
            <li>process monitoring</li>
            <li>log management</li>
            <li>clustering support</li>
            <li>zero downtime reloads</li>
            <li>background execution</li>
          </ul>
          
          <p>Think of PM2 as a supervisor that ensures your app never stops.</p>

          <h2>What is Nginx?</h2>
          <p>Nginx is a high-performance web server that acts as a reverse proxy.</p>
          
          <p>It sits in front of your application and handles incoming requests.</p>
          
          <p><strong>What Nginx does:</strong></p>
          <ul>
            <li>forwards client requests to backend server</li>
            <li>handles HTTPS/SSL</li>
            <li>load balancing</li>
            <li>caching</li>
            <li>security filtering</li>
            <li>serving static files</li>
          </ul>
          
          <p>In simple terms:</p>
          <pre><code>User â†’ Nginx â†’ Node.js App</code></pre>

          <h2>Use PM2 and Nginx Together</h2>
          <p>Both tools solve different problems.</p>
          
          <h3>PM2 â†’ manages application processes</h3>
          <ul>
            <li>keeps app running</li>
            <li>handles restarts</li>
            <li>manages multiple instances</li>
          </ul>

          <h3>Nginx â†’ manages incoming traffic</h3>
          <ul>
            <li>routes requests</li>
            <li>provides security</li>
            <li>handles HTTPS</li>
            <li>balances load</li>
          </ul>
          
          <p class="highlight">Together, they create a production-ready system.</p>

          <h2>Step-by-Step Deployment Guide</h2>

          <h3>Prerequisites</h3>
          <ul>
            <li>Linux server (Ubuntu/Debian recommended)</li>
            <li>Node.js installed</li>
            <li>Your application code</li>
            <li>Domain name (optional, but recommended)</li>
          </ul>

          <h3>Step 1: Install PM2</h3>
          <pre><code>npm install -g pm2</code></pre>

          <h3>Step 2: Start Application with PM2</h3>
          <pre><code># Start application
pm2 start app.js --name "my-app"

# Start with clustering (multiple instances)
pm2 start app.js -i max

# View running processes
pm2 list

# View logs
pm2 logs

# Monitor in real-time
pm2 monit</code></pre>

          <h3>Step 3: Configure PM2 Ecosystem File</h3>
          <p>Create <code>ecosystem.config.js</code> for better configuration:</p>
          <pre><code>module.exports = {
  apps: [{
    name: 'my-app',
    script: './app.js',
    instances: 'max',
    exec_mode: 'cluster',
    env: {
      NODE_ENV: 'production',
      PORT: 3000
    },
    error_file: './logs/err.log',
    out_file: './logs/out.log',
    log_date_format: 'YYYY-MM-DD HH:mm:ss',
    autorestart: true,
    watch: false,
    max_memory_restart: '1G'
  }]
};</code></pre>

          <p>Start using ecosystem file:</p>
          <pre><code>pm2 start ecosystem.config.js</code></pre>

          <h3>Step 4: Enable PM2 Startup Script</h3>
          <pre><code># Generate startup script
pm2 startup

# Save current running apps
pm2 save</code></pre>
          <p>This ensures PM2 starts automatically after server reboot.</p>

          <h3>Step 5: Install Nginx</h3>
          <pre><code>sudo apt update
sudo apt install nginx</code></pre>

          <h3>Step 6: Configure Nginx as Reverse Proxy</h3>
          <p>Create Nginx configuration file:</p>
          <pre><code>sudo nano /etc/nginx/sites-available/my-app</code></pre>

          <p>Add configuration:</p>
          <pre><code>server {
    listen 80;
    server_name yourdomain.com www.yourdomain.com;

    location / {
        proxy_pass http://localhost:3000;
        proxy_http_version 1.1;
        proxy_set_header Upgrade $http_upgrade;
        proxy_set_header Connection 'upgrade';
        proxy_set_header Host $host;
        proxy_cache_bypass $http_upgrade;
        proxy_set_header X-Real-IP $remote_addr;
        proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
        proxy_set_header X-Forwarded-Proto $scheme;
    }
}</code></pre>

          <h3>Step 7: Enable Configuration</h3>
          <pre><code># Create symbolic link
sudo ln -s /etc/nginx/sites-available/my-app /etc/nginx/sites-enabled/

# Test configuration
sudo nginx -t

# Restart Nginx
sudo systemctl restart nginx</code></pre>

          <h3>Step 8: Enable HTTPS with Let's Encrypt (Optional but Recommended)</h3>
          <pre><code># Install Certbot
sudo apt install certbot python3-certbot-nginx

# Get SSL certificate
sudo certbot --nginx -d yourdomain.com -d www.yourdomain.com

# Auto-renewal is configured automatically</code></pre>

          <h2>PM2 Essential Commands</h2>
          <pre><code># Start application
pm2 start app.js

# Stop application
pm2 stop my-app

# Restart application
pm2 restart my-app

# Delete from PM2
pm2 delete my-app

# View logs
pm2 logs my-app

# Zero downtime reload
pm2 reload my-app

# List all processes
pm2 list

# Monitor dashboard
pm2 monit

# Save process list
pm2 save

# Clear logs
pm2 flush</code></pre>

          <h2>Real-World Deployment Experience</h2>
          <p>In one of my production deployments for an e-commerce API:</p>
          <ul>
            <li>PM2 clustering handled <strong>10x more traffic</strong> than single process</li>
            <li>Automatic restarts prevented <strong>99.9% downtime</strong></li>
            <li>Nginx caching reduced server load by <strong>60%</strong></li>
            <li>HTTPS setup took only <strong>5 minutes</strong> with Certbot</li>
            <li>Zero downtime deployments using <code>pm2 reload</code></li>
          </ul>

          <h2>Best Practices</h2>
          <ul>
            <li><strong>Use ecosystem file</strong> for consistent configuration</li>
            <li><strong>Enable cluster mode</strong> to utilize all CPU cores</li>
            <li><strong>Set up proper logging</strong> with log rotation</li>
            <li><strong>Configure memory limits</strong> to prevent crashes</li>
            <li><strong>Use environment variables</strong> for sensitive data</li>
            <li><strong>Enable HTTPS</strong> for production</li>
            <li><strong>Set up monitoring</strong> with PM2 Plus or custom solutions</li>
            <li><strong>Configure rate limiting</strong> in Nginx</li>
            <li><strong>Regular backups</strong> of configurations</li>
            <li><strong>Test changes</strong> before deploying to production</li>
          </ul>

          <h2>Common Issues and Solutions</h2>

          <h3>Port Already in Use</h3>
          <p>Check and kill process using the port:</p>
          <pre><code>lsof -ti:3000 | xargs kill -9</code></pre>

          <h3>Nginx 502 Bad Gateway</h3>
          <p>Usually means Node.js app isn't running. Check PM2:</p>
          <pre><code>pm2 list
pm2 logs</code></pre>

          <h3>Application Crashing on Restart</h3>
          <p>Check logs and increase memory limit:</p>
          <pre><code>pm2 logs my-app --err
# Update max_memory_restart in ecosystem file</code></pre>

          <h2>Security Considerations</h2>
          <ul>
            <li>Keep Nginx and PM2 updated</li>
            <li>Configure firewall (UFW or iptables)</li>
            <li>Use strong SSL/TLS configurations</li>
            <li>Implement rate limiting</li>
            <li>Hide Nginx version in headers</li>
            <li>Set up fail2ban for brute force protection</li>
            <li>Regular security audits</li>
          </ul>

          <h2>Monitoring Your Application</h2>
          <p>Monitor critical metrics:</p>
          <ul>
            <li>CPU usage</li>
            <li>Memory consumption</li>
            <li>Response times</li>
            <li>Error rates</li>
            <li>Request rates</li>
            <li>Process restarts</li>
          </ul>

          <p>Use PM2 monitoring:</p>
          <pre><code>pm2 monit
# or sign up for PM2 Plus for web dashboard</code></pre>

          <h2>Conclusion</h2>
          <p>Deploying applications with PM2 and Nginx creates a robust, production-ready system. PM2 ensures your application runs continuously and handles failures gracefully, while Nginx provides efficient request routing, security, and performance optimization.</p>

          <p>This setup has proven reliable for handling production traffic, providing zero-downtime deployments, and ensuring high availability. Start with the basic configuration, then gradually add advanced features like clustering, caching, and monitoring as your application grows.</p>

          <p>Remember: A good deployment setup is as important as the application code itself. Invest time in getting it right from the start.</p>

          <p>Have you deployed applications using PM2 and Nginx? What challenges did you face?</p>
        </div>
      `,
    },
  };

  const post = blogPosts[id];

  if (!post) {
    return (
      <div className="blog-post-detail-container">
        <div className="post-not-found">
          <h1>Post Not Found</h1>
          <Link to="/blog" className="back-link">
            â† Back to Blog
          </Link>
        </div>
      </div>
    );
  }

  return (
    <div className="blog-post-detail-container">
      <Link to="/blog" className="back-link">
        â† Back to Blog
      </Link>

      <article className="blog-post-detail">
        <header className="post-detail-header">
          <h1 className="post-detail-title">{post.title}</h1>
          <div className="post-detail-meta">
            <span className="post-detail-date">{post.date}</span>
            <span className="post-detail-read-time">{post.readTime}</span>
          </div>
          <div className="post-detail-tags">
            {post.tags.map((tag, index) => (
              <span key={index} className="tag">
                {tag}
              </span>
            ))}
          </div>
        </header>

        <div
          className="post-detail-content"
          dangerouslySetInnerHTML={{ __html: post.content }}
        />
      </article>
    </div>
  );
};

export default BlogPostDetail;
